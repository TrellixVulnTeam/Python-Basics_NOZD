{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK \n",
    "NLTK stands for Natural Language Text Processing.\n",
    "Natural Language processing is about developing  application and services that are able to understand human language\n",
    "like speech recognition, speech transmission, text to speech splitting sentence from paragraph,splitting word line.\n",
    "To install NLTK :\n",
    "pip install nltk\n",
    "then,\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords          #stopwords contains helping words like is,are,in etc.\n",
    "sw=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "print(sw)\n",
    "print(len(sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "print(len(string.punctuation))\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"@python is an #easy to learn!!, powerful $programming and language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@phn  n #e  lern!!, pwerful $prgrng n lnguge\n"
     ]
    }
   ],
   "source": [
    "nsent=[x for x in sent if x not in sw]\n",
    "nsent=''.join(nsent)\n",
    "print(nsent)                      #here we compare character by character , that's why it is removing matching stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'python',\n",
       " 'is',\n",
       " 'an',\n",
       " '#',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'learn',\n",
       " '!',\n",
       " '!',\n",
       " ',',\n",
       " 'powerful',\n",
       " '$',\n",
       " 'programming',\n",
       " 'and',\n",
       " 'language']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word=word_tokenize(sent)                       #word_tokenize store word by word in the list \n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@phn#elern!!,pwerful$prgrnglnguge'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=[words for words in word if words not in sw]\n",
    "word=''.join(word)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phnelernpwerfulprgrnglnguge'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=[x for x in word if x not in string.punctuation]\n",
    "word=''.join(word)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The first question that comes in one’s mind is What is a microprocessor.', 'Let us start with a more familiar term computer.', 'A digital computer is an electronic machine capable of quickly performing a wide variety of tasks.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "abc=\"The first question that comes in one’s mind is What is a microprocessor. Let us start with a more familiar term computer. A digital computer is an electronic machine capable of quickly performing a wide variety of tasks.  \"\n",
    "print(sent_tokenize(abc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SYNONYMS AND ANTONYMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n",
      "moral excellence or admirableness\n",
      "['there is much good to be found in people']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syn=wordnet.synsets('good')\n",
    "print(syn)\n",
    "print(syn[1].definition())\n",
    "print(syn[1].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefit\n",
      "['for your own good', \"what's the good of worrying?\"]\n"
     ]
    }
   ],
   "source": [
    "print(syn[0].definition())\n",
    "print(syn[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having the normally expected amount\n",
      "['gives full measure', 'gives good measure', 'a good mile from here']\n"
     ]
    }
   ],
   "source": [
    "print(syn[5].definition())\n",
    "print(syn[5].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'good', 'goodness', 'good', 'goodness', 'commodity', 'trade_good', 'good', 'good', 'full', 'good', 'good', 'estimable', 'good', 'honorable', 'respectable', 'beneficial', 'good', 'good', 'good', 'just', 'upright', 'adept', 'expert', 'good', 'practiced', 'proficient', 'skillful', 'skilful', 'good', 'dear', 'good', 'near', 'dependable', 'good', 'safe', 'secure', 'good', 'right', 'ripe', 'good', 'well', 'effective', 'good', 'in_effect', 'in_force', 'good', 'good', 'serious', 'good', 'sound', 'good', 'salutary', 'good', 'honest', 'good', 'undecomposed', 'unspoiled', 'unspoilt', 'good', 'well', 'good', 'thoroughly', 'soundly', 'good']\n"
     ]
    }
   ],
   "source": [
    "synonyms=[]\n",
    "for syn in wordnet.synsets('good'):             #synsets used for synonyms\n",
    "    for lemma in syn.lemmas():\n",
    "        #print(lemma)\n",
    "        synonyms.append(lemma.name())\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
     ]
    }
   ],
   "source": [
    "antonyms=[]\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(antonyms)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gtts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8e6545bd431e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgtts\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgTTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mslow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gtts'"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "test=input('enter')\n",
    "language='en'\n",
    "obj=gTTS(text=test,lang=language,slow=False)\n",
    "obj.save('test.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:amaan\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    "def gender_features(word):\n",
    "    return{'last_letter':word[-1]}\n",
    "names=([(name,'male') for name in names.words\n",
    "       ('male.txt')]\n",
    "      +[(name,'female')\n",
    "       for name in names.words('female.txt')])\n",
    "featuresets=[(gender_features(n),g)\n",
    "            for (n,g) in names]\n",
    "train_set=featuresets\n",
    "classifier=nltk.NaiveBayesClassifier.train(train_set)\n",
    "name=input(\"Name:\")\n",
    "print(classifier.classify(gender_features(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neu: 0.16666666666666666\n",
      "positive:0.75\n",
      "negative: 0.08333333333333333\n",
      "movie is good\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "def word_feats(words):\n",
    "    return dict([(words,False)])\n",
    "positive_vocab=['awesome','outstanding','fantastic', 'terrific','good','nice','great',':)','better','best','excellent']\n",
    "negative_vocab=['bad','terrible','useless','hate',':(','not']\n",
    "neutral_vocab=['movie','the','sound','was','is','actors','did','know','words']\n",
    "positive_features=[(word_feats(pos),'pos')\n",
    "                 for pos in positive_vocab]\n",
    "#print(positive_feature)\n",
    "negative_features=[(word_feats(neg),'neg')\n",
    "                 for neg in negative_vocab]\n",
    "neutral_features=[(word_feats(neu),'neu')\n",
    "                 for neu in neutral_vocab]\n",
    "train_set=negative_features+positive_features+neutral_features\n",
    "nb=NaiveBayesClassifier.train(train_set)\n",
    "#predict\n",
    "neg=0\n",
    "pos=0\n",
    "neu=0\n",
    "sentence=\"Awesome movie Sound in not good But still its good in feature\"\n",
    "\n",
    "sentence=sentence.lower()\n",
    "words=sentence.split()\n",
    "for word in words:\n",
    "    classResult=nb.classify(\n",
    "    word_feats(word))\n",
    "    #print(word,classResult)\n",
    "    if classResult=='neg':\n",
    "        neg=neg+1\n",
    "    if classResult=='pos':\n",
    "        pos=pos+1\n",
    "    if classResult=='neu':\n",
    "        neu=neu+1\n",
    "#print(words)\n",
    "#print(pos)\n",
    "print('Neu: '+str(float(neu)/len(words)))\n",
    "print('positive:'+ str(float(pos)/len(words)))\n",
    "print('negative: '+str(float(neg)/len(words)))\n",
    "if neg>pos and neg>neu:\n",
    "    print(\"movie is not good\")\n",
    "elif pos>neg and pos>neu:\n",
    "    print(\"movie is good\")\n",
    "else:\n",
    "    print(\"one time you can see this movie \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install jdk8\n",
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
